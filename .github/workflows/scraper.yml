name: Streamwijzer Scraper

on:
  schedule:
    # Draait dagelijks om 18:00 UTC (= 19:00 Nederlandse tijd in winter, 20:00 in zomer)
    - cron: '0 18 * * *'
  
  # Handmatig triggeren via GitHub UI (voor testing)
  workflow_dispatch:

jobs:
  scrape-and-process:
    runs-on: ubuntu-latest
    
    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v4
    
    - name: ğŸ Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: ğŸ“¦ Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: ğŸ•·ï¸ Run scraper
      env:
        WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
      run: |
        python streamwijzer_scraper_automated.py
    
    - name: ğŸ’¾ Commit seen articles to repository
      if: always()
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add seen_articles.json
        git diff --quiet && git diff --staged --quiet || git commit -m "Update seen_articles.json [skip ci]"
        git push
    
    - name: ğŸ“Š Upload logs on failure
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: error-logs-${{ github.run_number }}
        path: |
          *.log
          *.txt
        retention-days: 7
    
    - name: ğŸ“ˆ Upload seen articles as backup
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: seen-articles-backup-${{ github.run_number }}
        path: seen_articles.json
        retention-days: 7
